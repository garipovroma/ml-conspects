 \section{Релевантность документа}
 \subsection{Понятие релевантности}
 Релевантность в информационном поиске — соответствие поискового намерения, заложенного в запросе, и выдачи в поисковой системе, полученной в результате этого запроса. Пользователь, который вводит запрос в поисковую систему ожидает, что результаты будут соответствовать намерению, которое он заложил в запросе, и он получит релевантную выдачу.

Существует несколько подходов к оценке релевантности: 
\begin{itemize}
    \item Содержательная релевантность — соответствие ответов информационному запросу, определяемое неформальным путём. 
    \item Формальная релевантность — соответствие, определяемое путём сравнения образа поискового запроса с поисковым образом ответа по определённому алгоритму.
\end{itemize}

 \subsection{TF-IDF-метод}
Одним из распространённых методов для оценки релевантности является TF-IDF-метод. Его смысл сводится к тому, что чем больше локальная частота термина (запроса) в документе (TF) и больше «редкость» (то есть, чем реже он встречается в других документах) термина в коллекции (IDF), тем выше вес данного ответа по отношению к термину — то есть ответ будет выдаваться раньше в результатах поиска по данному термину. Автор метода — Джерард Солтон, в дальнейшем доработан Карен Спарк Джонс.

\subsection{Факторы, влияющие на релевантность}
Факторы, которые оказывают влияние на релевантность, принято делить на внешние и внутренние. К внешним относят ссылочную массу, к внутренним — технические составляющие и содержимое.

\begin{itemize}
    \item Ссылочная масса. Чем больше тематических и качественных ссылок ведёт на страницы ресурса, тем больше вероятность ценности ресурса для пользователя.
    \item Технические составляющие. Большая группа параметров, по которым поисковая система оценивает как сайт в целом, так и отдельные страницы (например, наличие метатегов, отсутствие ошибок в HTML-разметке и так далее).
    \item Контент. Ключевой фактор от которого зависит релевантность страницы и конверсия.
\end{itemize}

\subsection{Ранжирование}
Ранжирование — это сортировка каких-либо объектов из соображения их относительной релевантности («важности»).
Как измерять качество ранжирования.

У ранжируемых объектов есть какое-то число  $r_i$ , соответствующее «эталонной» релевантности. Существует два основных способа его получения:

\begin{itemize}
    \item На основе исторических данных. Например, в случае рекомендаций контента, можно взять просмотры (клики, лайки, покупки) пользователя и присвоить просмотренным весам соответствующих элементов 1, а всем остальным — 0.
    \item На основе экспертной оценки. Например, в задаче поиска, для каждого запроса можно привлечь команду асессоров, которые вручную оценят релевантности документов запросу. Обычно оценка категориальная (то есть не действительное число, а несколько градаций, скажем, 2, 3 или 5).
\end{itemize}

\subsection{Метрики ранжирования}
Дальше возникает задача оценить качество ранжирования в целом, уже имея информацию о релевантности каждого элемента по отдельности. Условно, от идеального ранжирования мы хотим, чтобы объекты шли в порядке убывания релевантности, но есть несколько способов задать такие метрики.

Precision at k (p@k) — «точность на  K  элементах». Допустим, наш алгоритм ранжирования выдал оценки релевантности для каждого элемента. Отобрав среди них первые  k  элементов с наибольшим  ri  посчитаем среди них долю релевантных — это и называется precision at k.

MRR - mean reciprocal rank, дословно «средний обратный ранг».
Эта метрика никак не учитывает абсолютные значения релевантности, а только их относительный порядок. Пусть $i$ -тый самый релевантный элемент в нашем упорядочивании оказался на позиции $\operatorname{ran} k_{i} \in[1, N] .$ Тогда MRR считается как:
$$
M R R @ k=\frac{1}{K} \sum_{i=1}^{K} \frac{1}{\operatorname{rank}_{i}}
$$

Чаще всего считают MRR@1, то есть просто по большому количеству запросов смотрят, на какой позиции находится самый подходящий документ, и усредняют обратные к этим позициям.

DCG - discounted cumulative gain. Учитывает одновременно и значения релевантностей, и их порядок, путем домножения
релевантности на вес, равный обратному логарифму номера позиции:
$$
D C G=\sum_{i=1}^{N} \frac{r e l_{i}}{\log _{2}(i+1)}
$$
у неё есть проблема, связанная с тем, что, по-первых, оценки релевантности могут быть неотмасштабированными, и, во-вторых, на больших последовательностях она выше.
Поэтому вводят $n D C G$ («нормализованный DCG» принимающий значения от о до 1), равный отношению DCG данного
ранжирования к «идеальному», то есть максимально возможному (iDCG):
$$
n D C G=\frac{D C G}{i D C G}
$$
iDCG можно получить, отсортировав выдачу по реальным релевантностям и посчитав DCG на нём.

pFound. В Яндексе для поисковых задач когда-то придумали и до сих пор повсеместно используют метрику, которая называется pfound - грубо говоря, вероятность того, что пользователь найдёт на странице выдачи (среди первых $n$ документов) то, что искал.
$$
\text { pfound }=\sum_{i=1}^{n} p \operatorname{Look}(i) \cdot p \operatorname{Rel}(i)
$$
Где $p$ Look определяется рекурсивно, как вероятность того, что пользователь вообще посмотрит на $\boldsymbol{i}$ -тый документ:
$$
p \operatorname{Look}(i)=\left\{\begin{array}{ll}
1, & i=1 \\
p \operatorname{Look}(i-1) \cdot(1-p \operatorname{Rel}(i-1)), & i>1
\end{array}\right.
$$
Интуиция такая: пользователь просматривает страницы выдачи сверху вниз, пока не найдёт релевантный документ, вероятность чего равна $p \operatorname{Rel}(i)=f\left(r_{i}\right)$, то есть как-то зависит от асессорской оценки релевантности.